{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a9167b-ab5b-413d-bbdd-a136e7160c1a",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch for MNIST Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ce68f-976d-40be-990b-bc70b67c3487",
   "metadata": {},
   "source": [
    "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that contains 60,000 training images and 10,000 testing images. \n",
    "\n",
    "<img src=\"DL1.png\" width = \"500\" height = \"340\">\n",
    "\n",
    "          Sample images from MNIST test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d38af9-b14d-4706-89dc-f4b01f097ae3",
   "metadata": {},
   "source": [
    " Here, the MNIST database is used for training and testing our Convolutional Neural Network. A convolutional neural network (CNN) is a specialized form of feed-forward neural network that autonomously identifies features through the optimization of filters (or kernels). This deep learning architecture has been utilized to analyze and predict outcomes from various data types, such as text, images, and audio. Its application in geoscience, especially in seismic interpretation is rapidly expanding, reflecting its growing significance in these fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f194c-4cbf-42ca-8286-72a09b09e81e",
   "metadata": {},
   "source": [
    "A convolutional neural network is made up of an input layer, multiple hidden layers, and an output layer. Within a convolutional neural network, the hidden layers feature one or more layers responsible for performing convolutions. Generally, this involves a layer that computes the dot product between the convolution kernel and the input matrix from the previous layer. This computation typically results in the Frobenius inner product, with the activation function often being ReLU. As the convolution kernel moves across the input matrix, the convolution process produces a feature map that serves as input for the subsequent layer. This is succeeded by additional layers, which may include pooling layers, fully connected layers, and normalization layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad8cfa-fda9-4808-bd37-9355add5400b",
   "metadata": {},
   "source": [
    "<img src=\"DL2.jpg\" width = \"500\" height = \"340\">\n",
    "\n",
    "              Typical CNN architecture\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0d135-61d8-4698-ac1b-06ba82457116",
   "metadata": {},
   "source": [
    "Now before we start, it is important to note that every data in MNIST images point has two parts: an image (x) and a corresponding label (y) describing the actual image and each image is a 28x28 array, i.e., 784 numbers. The label of the image is a number between 0 and 9 corresponding to the TensorFlow MNIST image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a7226-9fa8-44e2-a13b-8aff1ecf37f1",
   "metadata": {},
   "source": [
    "<img src=\"DL3.png\" width = \"500\" height = \"340\">\n",
    "\n",
    "          Sample MNIST dataset in TensorFlow\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6afff-ff01-4fb4-8ef9-a86a2bcb2c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac37ed-50f7-4ca5-8c28-34f79381bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert MNIST image dataset into a 4D (# of images, height, width, colour channels)\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root= '/cnn_data', train= True, download= True, transform=transform)\n",
    "test_data = datasets.MNIST(root= '/cnn_data', train= False, download= True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005e95b-8d50-4201-8ee3-7f80f928450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle= True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17cf7f-e512-418a-893e-d4e3ef552db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Class\n",
    "class MYCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        # fully connected NN\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "        # Review to flattern it out\n",
    "        x = x.view(-1, 16*5*5) #Negative one so we can vary the batch size\n",
    "\n",
    "        #Fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return  F.log_softmax(x, dim=1)\n",
    "\n",
    "# creat an instance of our model\n",
    "torch.manual_seed(41)\n",
    "\n",
    "model = MYCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda043f-3e37-40b6-b66e-dfe03b3e363f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad61c6d-d3f1-4741-b770-a4949d404b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the criterion of model to measure the error\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# choose optimization, lr = learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    test_corr = 0\n",
    "\n",
    "    # train\n",
    "    for b, (x_train, y_train) in enumerate(train_loader):\n",
    "        b+=1 #start our batches at 1\n",
    "\n",
    "        # Go forward and get a prediction\n",
    "        y_pred = model.forward(x_train)\n",
    "\n",
    "        # Measure the loss\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "        # add up the number of correct predictions. Indexed of the first point\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "\n",
    "        #how many we got correct\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "\n",
    "        #keep track along training\n",
    "        trn_corr += batch_corr\n",
    "\n",
    "        # back propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print out some results\n",
    "        if b % 600 ==0:\n",
    "            print(f'Epoch: {i} batch: {b} and loss: {loss.item()}')\n",
    "\n",
    "    train_correct.append(trn_corr)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    #test\n",
    "    with torch.no_grad():\n",
    "        for b, (x_test, y_test) in enumerate(test_loader):\n",
    "            b += 1\n",
    "            y_val = model(x_test)\n",
    "            #Adding up correct prediction\n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            test_corr += (predicted == y_test).sum()\n",
    "\n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(test_corr)\n",
    "\n",
    "\n",
    "current_time = time.time()\n",
    "total = current_time - start_time\n",
    "print(f'Training Took: {total/60} minutes!')\n",
    "\n",
    "test_load_everything = DataLoader(test_data, batch_size=10000, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_everything:\n",
    "        y_val = model(X_test)\n",
    "        predicted = torch.max(y_val, 1)[1]\n",
    "        correct += (predicted == y_test).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1cf68e-f47e-420e-a23e-ee30d830bcb9",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359ee69-caca-45b2-8ab5-0b20f1eecb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "Accuracy = correct.item() / len(test_data) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba4d477-9f68-4cb6-bb87-578962f691f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.6199999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f9c0d6-b7f9-4225-af98-b68e46143b76",
   "metadata": {},
   "source": [
    "### Losses Tracjing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5c1bd-a49f-470a-b240-ddb741f16ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [tl.item() for tl in train_losses]\n",
    "plt.plot(train_losses, label= \"train_losses\")\n",
    "plt.plot(test_losses, label= \"test_losses\")\n",
    "plt.title(\"loss at epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2552fc-3d4e-43de-b4aa-4b387e691185",
   "metadata": {},
   "source": [
    "<img src=\"DL4.png\" width = \"500\" height = \"340\">\n",
    "\n",
    "          Train and test losses after 10 epochs\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e2c683-dd8f-4cf6-8963-d1269191c893",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9002464b-6662-45ed-82e9-efc402bc6d87",
   "metadata": {},
   "source": [
    "Predict New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad90583-88ba-40e9-ac48-9d5c738c0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_data[4142][0].view(28, 28).numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b333851e-3ca4-40d5-abdc-135dc0347f75",
   "metadata": {},
   "source": [
    "<img src=\"DL5.png\" width = \"500\" height = \"340\">\n",
    "\n",
    "      A new image has been loaded for testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058dcb45-3e84-494b-958f-a2a91ba18647",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_prediction = model(test_data[4142][0].view(1, 1, 28, 28)) \n",
    "\n",
    "new_prediction = new_prediction.argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c7fa18b-20e6-4e43-a359-515a992fb33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fa058-5574-4369-a321-621b9eddee31",
   "metadata": {},
   "source": [
    "The model successfully predicts the number of handwritings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
